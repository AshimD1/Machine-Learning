# -*- coding: utf-8 -*-
"""Keras regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qaCdC0EFtaZoSW7BG-HuKDMCRAQ_TRsr
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv ('/content/kc_house_data.csv')

df.head()

df.isnull()

df.isnull().any()

df.isnull().sum()

df.describe()

df.describe().transpose()

df.head()

plt.figure(figsize = (10,6))
sns.distplot(df['price'])

sns.countplot(x=  'bedrooms', data=df)

plt.figure(figsize=(10,5))
sns.scatterplot(x='price', y='sqft_living', data=df)

plt.figure(figsize=(10,6))
sns.boxplot(x='bedrooms', y='price', data=df)

df.columns

plt.figure(figsize=(10,6))
sns.scatterplot(x='price',y='long',data=df)

plt.figure(figsize=(10,6))
sns.scatterplot(x='price',y='lat',data=df)

plt.figure(figsize=(10,6))
sns.scatterplot(x='long',y='lat',data=df, hue = 'price')

df.sort_values('price',ascending =False).head(20)

len(df)*0.01

non_top_1_perc = df.sort_values('price',ascending =False).iloc[216:]

plt.figure(figsize=(10,6))
sns.scatterplot(x='long',y='lat',data=non_top_1_perc,edgecolor=None, alpha = 0.2,palette='RdYlGn', hue = 'price')

plt.figure(figsize=(10,6))
sns.boxplot(x='waterfront',y='price',data=df)

df.head()

df = df.drop('id',axis=1)

df.head()

df['date'] = pd.to_datetime(df['date'])

df['date']

# def year_extraction(date):
#   return date.year

df['year'] = df['date'].apply(lambda date: date.year)
df['month'] = df['date'].apply(lambda date: date.month)

df.head()

plt.figure(figsize = (10,6))
sns.boxplot(x='month', y= 'price', data=df)

df.groupby('month').mean()['price']

df.groupby('month').mean()['price'].plot()

df.groupby('year').mean()['price'].plot()

df = df.drop('date',axis=1)

df.head()

df.head().transpose()

df['zipcode'].value_counts()

df= df.drop('zipcode',axis = 1)

df['yr_renovated'].value_counts()

df['sqft_basement'].value_counts()

x = df.drop('price',axis =1).values
y = df['price'].values

from sklearn.model_selection import train_test_split

x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.3, random_state = 101)

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

x_train = scaler.fit_transform(x_train)

x_test = scaler.transform(x_test)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

x_train.shape

model = Sequential()

model.add(Dense(19,activation = 'relu'))
model.add(Dense(19,activation = 'relu'))
model.add(Dense(19,activation = 'relu'))
model.add(Dense(19,activation = 'relu'))

model.add(Dense(1))

model.compile(optimizer= 'adam', loss= 'mse')

model.fit(x=x_train,y=y_train,validation_data=(x_test,y_test),
          batch_size = 128,epochs = 400)

model.history.history

losses = pd.DataFrame(model.history.history)

losses.plot()

from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score

predictions = model.predict(x_test)

predictions

mean_squared_error(y_test,predictions)

np.sqrt(mean_squared_error(y_test,predictions))

mean_absolute_error(y_test,predictions)

df['price'].describe()

explained_variance_score(y_test,predictions)

plt.figure(figsize=(12,6))
plt.scatter(y_test,predictions)
plt.plot(y_test,y_test,'r')

df

single_house = df.drop('price',axis=1).iloc[0]

single_house = scaler.transform(single_house.values.reshape(-1,19))

model.predict(single_house)

df.head(1)

